#MS1
#initializing variables

##tolerances and population sizes
#!!define the tolerance schedule (epsilon/e here)
e <- 
  
T <- length(e)    #populations count
N <- 1000         #particles count

### priors for models and parameters
models <- 1:2  #for 2 model count
pprior <- list(
  #!!update this as per the required prior distribution
  #assuming  U(0,100) here
  m1 = function() runif(1, 0, 100),  #if uniform prior for Model 1
  m2 = function() runif(1, 0, 100)   #if uniform prior for Model 2
)

###transition probs
#!!set the model transition probss as per requirement of the dataset's models
tp <- matrix(c(
  0.8, 0.2,  #model 1
  0.2, 0.8   #model 2
), nrow = 2, byrow = TRUE)


###observed data
#!!define variable for observed data
D0<-

###initializing storage for particles and weights
particles <- vector("list", T)
wts <- vector("list", T)


###initializing 1st population
particles[[1]] <- lapply(1:N, function(i) {
  model <- sample(models, 1)  #prior model
  #sample parameter:
  parameter <- pprior[[paste0("m", model)]]()  #pprior: prior parameters
  list(model = model, parameter = parameter)
})
wts[[1]] <- rep(1 / N, N)  #considerng unifrm weights for the first population




###defining rudimentary functions

#### distance function: mean-squared error
distance <- function(D0, D_star) {
  return(sum((D0 - D_star)^2))
}


###model perturbation
##!!this will probably remain as is
#refined model:
refined <- function(m, models, tp) {
return(sample(models, 1, prob = tp[m, ]))  
}


###parameter perturbation
#sig: standard deviation
#!!adjust kernels as per the model
#perturb parameters
perturb <- function(theta, sig) { 
  return(rnorm(1, mean = theta, sd = sig)) 
  #gaussian perturbation since smc
}


###data simulation function
##!! insert model parameters
#simulate data: sim
sim <- function(model, parameter) {
  if (model == 1) {
    #insert model1 parameters (x,y)
    
  } else {
    #insert model2 parameters
  }
}


compute_S <- function(model_star, parameter_star, particles_prev, wts_prev, models, sd_param) {
  # Compute prior probability
  prior_prob <- prior_probability(model_star, parameter_star, models)
  
  #computing normalization constant
  normalization <- sum(sapply(1:length(particles_prev), function(j) {
    if (particles_prev[[j]]$model == model_star) {
      perturb_prob <- dnorm(
        parameter_star, 
        mean = particles_prev[[j]]$parameter, 
        sd = sd_param
      ) #perturbation kernel
      return(perturb_prob * wts_prev[j])
    } else {
      return(0)
    }
  }))
  
  #computing particle weight
  if (normalization > 0) {
    return(prior_prob / normalization)
  } else {
    return(0) # Handle cases where normalization is zero
  }
}

#cCompute prior probability for a given model and parameter
prior_probability <- function(model, parameter, models) {
  #evaluating prior probability based on model and prior distribution
  if (model == 1) {
    return(dunif(parameter, min = 0, max = 100)) # Uniform prior for Model 1
  } else if (model == 2) {
    return(dunif(parameter, min = 0, max = 100)) # Uniform prior for Model 2
  }
}



#MS2
#sequential sampling + refinement

for (t in 2:T) {
  particles[[t]] <- vector("list", N)
  wts[[t]] <- numeric(N)
  
  for (i in 1:N) {
    repeat {
      #resampling + refining
      idx <- sample(1:N, 1, prob = wts[[t - 1]])  #resampling from prev population
      model_star <- refined( #refining
        particles[[t - 1]][[idx]]$model, models, tp
      )
      parameter_star <- perturb(
        particles[[t - 1]][[idx]]$parameter,
        sd = 2 * diff(range(unlist(lapply(particles[[t - 1]], function(p) p$parameter))))
      )
      
      #simulating candidate dataset
      D_star <- sim(model_star, parameter_star)
      
      #checking acceptance
      if (distance(D0, D_star) <= e[t]) {
        particles[[t]][[i]] <- list(model = model_star, parameter = parameter_star)
        break
      }
    }
    
    #computing weights
    wts[[t]][i] <- compute_S(
      model_star = particles[[t]][[i]]$model,
      parameter_star = particles[[t]][[i]]$parameter,
      particles_prev = particles[[t - 1]],
      wts_prev = wts[[t - 1]],
      models = models,
      sd_param = sig
    )
  }
  
  #normalizing weights
  wts[[t]] <- wts[[t]] / sum(wts[[t]])
  
  #handling degeneracy w ESS
  ESS <- 1 / sum(wts[[t]]^2)
  if (ESS < N / 2) {
    indices <- sample(1:N, N, replace = TRUE, prob = wts[[t]])
    particles[[t]] <- particles[[t]][indices]
    wts[[t]] <- rep(1 / N, N)
  }
  
  #fallback for e[t] in case no acceptable particles
  if (all(sapply(1:N, function(i) distance(D0, sim(
    particles[[t]][[i]]$model, particles[[t]][[i]]$parameter))) > e[t])) {
    e[t] <- e[t] * 1.5  #relaxing tolerance
  }
}



#MS3 computing posterior probs

#computing posterior probs
posterior <- sapply(models, function(m) {
  sum(sapply(1:N, function(i) {
    if (particles[[T]][[i]]$model == m) {
      wts[[T]][i]
    } else {
      0
    }
  }))
})

posterior <- posterior / sum(posterior)  #normalizing
print(posterior)




#viz
###tolerance schedule
plot(1:T, e, type = "b", main = "Tolerance Schedule", xlab = "Population", ylab = "Epsilon")

###ess evolution
plot(1:T, sapply(1:T, function(t) 1 / sum(wts[[t]]^2)), type = "b", 
     main = "Effective Sample Size (ESS)", xlab = "Population", ylab = "ESS")

###posterior parameter distribution plot
hist(unlist(lapply(particles[[T]], function(p) p$parameter)),
     breaks = 20, main = "Posterior Distribution", xlab = "Parameter Values")
